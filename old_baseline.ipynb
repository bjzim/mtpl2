{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:  \n",
    "- aufsummieren der idpol-duplikate  anstelle dropping  \n",
    "- Zielvariable ist claimamount / exposure  \n",
    "- EDA selbst plotten  \n",
    "- model fitting mit sample_weight=exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ziel dieses notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gegebenen Datasets stellen viele Fragen. Dieses Notebook hat als Ziel, sehr schnell zu einem Modell zu kommen. Womöglich mit deutlichen Ungenauigkeiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiere Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sev = pd.read_csv('data/df_sev.csv', index_col=0)\n",
    "df_freq = pd.read_csv(\"data/df_freq.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpol</th>\n",
       "      <th>claimamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1552.0</td>\n",
       "      <td>995.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010996.0</td>\n",
       "      <td>1128.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4024277.0</td>\n",
       "      <td>1851.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4007252.0</td>\n",
       "      <td>1204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4046424.0</td>\n",
       "      <td>1204.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idpol  claimamount\n",
       "0     1552.0       995.20\n",
       "1  1010996.0      1128.12\n",
       "2  4024277.0      1851.11\n",
       "3  4007252.0      1204.00\n",
       "4  4046424.0      1204.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpol</th>\n",
       "      <th>claimnb</th>\n",
       "      <th>exposure</th>\n",
       "      <th>area</th>\n",
       "      <th>vehpower</th>\n",
       "      <th>vehage</th>\n",
       "      <th>drivage</th>\n",
       "      <th>bonusmalus</th>\n",
       "      <th>vehbrand</th>\n",
       "      <th>vehgas</th>\n",
       "      <th>density</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>'D'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>'B12'</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>'R82'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>'D'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>'B12'</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>'R82'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>'B'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>'B12'</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>54.0</td>\n",
       "      <td>'R22'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>'B'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>'B12'</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76.0</td>\n",
       "      <td>'R72'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>'B'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>'B12'</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76.0</td>\n",
       "      <td>'R72'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idpol  claimnb  exposure area  vehpower  vehage  drivage  bonusmalus   \n",
       "0    1.0      1.0      0.10  'D'       5.0     0.0     55.0        50.0  \\\n",
       "1    3.0      1.0      0.77  'D'       5.0     0.0     55.0        50.0   \n",
       "2    5.0      1.0      0.75  'B'       6.0     2.0     52.0        50.0   \n",
       "3   10.0      1.0      0.09  'B'       7.0     0.0     46.0        50.0   \n",
       "4   11.0      1.0      0.84  'B'       7.0     0.0     46.0        50.0   \n",
       "\n",
       "  vehbrand   vehgas  density region  \n",
       "0    'B12'  Regular   1217.0  'R82'  \n",
       "1    'B12'  Regular   1217.0  'R82'  \n",
       "2    'B12'   Diesel     54.0  'R22'  \n",
       "3    'B12'   Diesel     76.0  'R72'  \n",
       "4    'B12'   Diesel     76.0  'R72'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_sev.head(), df_freq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  4.,  3., 11.,  0.,  5.,  6.,  8., 16.,  9.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq['claimnb'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datentypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_sev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_sev hat zwei Spalten. \n",
    "\n",
    "- Einmal die Spalte der Policenummer ('**idpol**') und dann \n",
    "- die Spalte der fälligen Aufwendungen für Versicherungsfälle ('**claimamount**')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26639 entries, 0 to 26638\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   idpol        26639 non-null  float64\n",
      " 1   claimamount  26639 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 624.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_sev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemischte Datentypen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'idpol' hat den Datentyp: <class 'float'>\n",
      "Spalte 'claimamount' hat den Datentyp: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for column in df_sev.columns:\n",
    "    mixed_types = df_sev[column].apply(type).unique()\n",
    "    \n",
    "    if len(mixed_types) > 1:\n",
    "        print(f\"Spalte '{column}' hat gemischte Datentypen: {mixed_types}\")\n",
    "    else:\n",
    "        print(f\"Spalte '{column}' hat den Datentyp: {mixed_types[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beide Spalten liegen derzeit als Float 64 vor. \n",
    "\n",
    "- **idpol** ist *float64*, wird in *integer* umgewandelt, da categorical keinen Nutzen bringt.\n",
    "- **claimamount** bleibt *float64*, um Genauigkeit zu behalten - auf Kosten der Rechner-Performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anpassung idpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sev['idpol'] = df_sev['idpol'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26639 entries, 0 to 26638\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   idpol        26639 non-null  int32  \n",
      " 1   claimamount  26639 non-null  float64\n",
      "dtypes: float64(1), int32(1)\n",
      "memory usage: 520.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_sev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_freq hat 12 Spalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 678013 entries, 0 to 678012\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   idpol       678013 non-null  float64\n",
      " 1   claimnb     678013 non-null  float64\n",
      " 2   exposure    678013 non-null  float64\n",
      " 3   area        678013 non-null  object \n",
      " 4   vehpower    678013 non-null  float64\n",
      " 5   vehage      678013 non-null  float64\n",
      " 6   drivage     678013 non-null  float64\n",
      " 7   bonusmalus  678013 non-null  float64\n",
      " 8   vehbrand    678013 non-null  object \n",
      " 9   vehgas      678013 non-null  object \n",
      " 10  density     678013 non-null  float64\n",
      " 11  region      678013 non-null  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 67.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_freq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemischte Datentypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir prüfen auf gemischte Datentypen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'idpol' hat den Datentyp: <class 'float'>\n",
      "Spalte 'claimnb' hat den Datentyp: <class 'float'>\n",
      "Spalte 'exposure' hat den Datentyp: <class 'float'>\n",
      "Spalte 'area' hat den Datentyp: <class 'str'>\n",
      "Spalte 'vehpower' hat den Datentyp: <class 'float'>\n",
      "Spalte 'vehage' hat den Datentyp: <class 'float'>\n",
      "Spalte 'drivage' hat den Datentyp: <class 'float'>\n",
      "Spalte 'bonusmalus' hat den Datentyp: <class 'float'>\n",
      "Spalte 'vehbrand' hat den Datentyp: <class 'str'>\n",
      "Spalte 'vehgas' hat den Datentyp: <class 'str'>\n",
      "Spalte 'density' hat den Datentyp: <class 'float'>\n",
      "Spalte 'region' hat den Datentyp: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for column in df_freq.columns:\n",
    "    mixed_types = df_freq[column].apply(type).unique()\n",
    "    \n",
    "    if len(mixed_types) > 1:\n",
    "        print(f\"Spalte '{column}' hat gemischte Datentypen: {mixed_types}\")\n",
    "    else:\n",
    "        print(f\"Spalte '{column}' hat den Datentyp: {mixed_types[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es liegen keine gemischten Datentypen vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5.0\n",
       "1         5.0\n",
       "2         6.0\n",
       "3         7.0\n",
       "4         7.0\n",
       "         ... \n",
       "678008    4.0\n",
       "678009    4.0\n",
       "678010    6.0\n",
       "678011    4.0\n",
       "678012    7.0\n",
       "Name: vehpower, Length: 678013, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq['vehpower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **idpol** ist *float* und soll *string* sein [Skalenniveau: nominal].\n",
    "- **claimnb** ist *float* und soll *integer* sein [Skalenniveau: verhältnis, diskret].\n",
    "- **exposure** ist *float* und soll *integer* sein. [Skalenniveau: verhältnis, diskret]\n",
    "- **area** ist *string* und soll *string* bleiben. [Skalenniveau: nominal - Strings sind zu bereinigen]\n",
    "- **vehpower** ist *float*, sollte *categorical* werden [Skalenniveau: ordinal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anpassung der Datentypen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplikate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_sev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26639 entries, 0 to 26638\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   idpol        26639 non-null  int32  \n",
      " 1   claimamount  26639 non-null  float64\n",
      "dtypes: float64(1), int32(1)\n",
      "memory usage: 520.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_sev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hat df_sev Duplikate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Duplikate in df_sev: 255\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df_sev.duplicated().sum()\n",
    "print(f\"Anzahl der Duplikate in df_sev: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem notebook entfernen wir einfach die Duplikate. Als Duplikat gilt, wenn die gesamte Datenreihe mehr als einmal vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sev.drop_duplicates(keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Duplikate in df_sev: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df_sev.duplicated().sum()\n",
    "print(f\"Anzahl der Duplikate in df_sev: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 678013 entries, 0 to 678012\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   idpol       678013 non-null  float64\n",
      " 1   claimnb     678013 non-null  float64\n",
      " 2   exposure    678013 non-null  float64\n",
      " 3   area        678013 non-null  object \n",
      " 4   vehpower    678013 non-null  float64\n",
      " 5   vehage      678013 non-null  float64\n",
      " 6   drivage     678013 non-null  float64\n",
      " 7   bonusmalus  678013 non-null  float64\n",
      " 8   vehbrand    678013 non-null  object \n",
      " 9   vehgas      678013 non-null  object \n",
      " 10  density     678013 non-null  float64\n",
      " 11  region      678013 non-null  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 67.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_freq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hat df_freq Duplikate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Duplikate in df_freq: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df_freq.duplicated().sum()\n",
    "print(f\"Anzahl der Duplikate in df_freq: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenführung der Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir in diesem Notebook sehr zügig zu einem Modell kommen wollen, interessieren uns nur die Versicherungspolicen, denen ein Schadensaufwand zugeordnet werden konnte. Und es interessiert uns nur ein Schadensaufwand, dem Eigenschaften der Versicherungsfälle zugeordnet werden können. df_sev ist also im Lead - da claimamount die Zielvariable ist - und wir nutzen hier einen inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sev.merge(df_freq, on='idpol', how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 679254 entries, 0 to 679253\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   idpol        679254 non-null  float64\n",
      " 1   claimamount  25980 non-null   float64\n",
      " 2   claimnb      679254 non-null  float64\n",
      " 3   exposure     679254 non-null  float64\n",
      " 4   area         679254 non-null  object \n",
      " 5   vehpower     679254 non-null  float64\n",
      " 6   vehage       679254 non-null  float64\n",
      " 7   drivage      679254 non-null  float64\n",
      " 8   bonusmalus   679254 non-null  float64\n",
      " 9   vehbrand     679254 non-null  object \n",
      " 10  vehgas       679254 non-null  object \n",
      " 11  density      679254 non-null  float64\n",
      " 12  region       679254 non-null  object \n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 67.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['claimamount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schnelle EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nutzen ydata profiling um den Dataframe zu analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "#profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multikollinearität - Korrelationen der unabhängigen Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drivage** is highly overall correlated with **bonusmalus**  \n",
    "**bonusmalus** is highly overall correlated with **drivage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da **bonusmalus** als abhängig von **drivage** eingeschätzt wird (Kausalität), wird **bonusmalus entfernt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('bonusmalus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**density** is highly overall correlated with **area**  \n",
    "**area** is highly overall correlated with **density**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1217.,   54.,   76., ..., 1036., 1013.,  908.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['density'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'D'\", \"'B'\", \"'E'\", \"'C'\", \"'F'\", \"'A'\"], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['area'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der area-code (**area**) als abhängig von **density** eingeschätzt wird (Kausalität), wird der **area** entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('area', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es bleiben also folgende Features übrig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 679254 entries, 0 to 679253\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   idpol        679254 non-null  float64\n",
      " 1   claimamount  679254 non-null  float64\n",
      " 2   claimnb      679254 non-null  float64\n",
      " 3   exposure     679254 non-null  float64\n",
      " 4   vehpower     679254 non-null  float64\n",
      " 5   vehage       679254 non-null  float64\n",
      " 6   drivage      679254 non-null  float64\n",
      " 7   vehbrand     679254 non-null  object \n",
      " 8   vehgas       679254 non-null  object \n",
      " 9   density      679254 non-null  float64\n",
      " 10  region       679254 non-null  object \n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 57.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schnelle EDA (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "#profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**claimamount** ist rechtsschief. Wir ignorieren dies zunächst.\n",
    "\n",
    "**vehage** hat 1173 Nullwerte. Das ist nicht schlimm, da es Autos gibt die jünger als ein Jahr sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letzte Datenbereinigung vor dem Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Nummer der Versicherungspolice offensichtlich keinen Einfluss auf den Schadensaufwand haben wird, lassen wir diese als Feature fallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('idpol', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_copy['claimamount']\n",
    "X = df_copy.drop('claimamount', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543403, 9) (543403,)\n",
      "(135851, 9) (135851,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellwahl und Vorbereitungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich entscheide mich für **XGboost** als Gradient Boosting Model. Die lineare Regression ist nicht interessant, da ich nicht von linearen Zusammenhängen ausgehe. XGboost ist auch skalierungsunempflindlich, was helfen könnte wegen der schiefe der zielvariablen. Außerdem kann ich es über die GPU laufen lassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding der categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claimnb     0\n",
       "exposure    0\n",
       "vehpower    0\n",
       "vehage      0\n",
       "drivage     0\n",
       "vehbrand    0\n",
       "vehgas      0\n",
       "density     0\n",
       "region      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocessing X_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehbrand    0\n",
       "vehgas      0\n",
       "region      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = OneHotEncoder() #Objektinstanz Encoder\n",
    "\n",
    "categorical_columns = ['vehbrand','vehgas','region'] #Definition Categorical Variables\n",
    "\n",
    "encoded_data = one_hot.fit_transform(X_train[categorical_columns]).toarray() # Fitting und Encoding von allen cat. Variablen und Zuordnug zu encoded_df\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=one_hot.get_feature_names_out(categorical_columns))\n",
    "\n",
    "train_cat_df = X_train[categorical_columns]\n",
    "train_cat_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, encoded_df], axis=1).drop(categorical_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claimnb           0\n",
       "exposure          0\n",
       "vehpower          0\n",
       "vehage            0\n",
       "drivage           0\n",
       "density           0\n",
       "vehbrand_'B1'     0\n",
       "vehbrand_'B10'    0\n",
       "vehbrand_'B11'    0\n",
       "vehbrand_'B12'    0\n",
       "vehbrand_'B13'    0\n",
       "vehbrand_'B14'    0\n",
       "vehbrand_'B2'     0\n",
       "vehbrand_'B3'     0\n",
       "vehbrand_'B4'     0\n",
       "vehbrand_'B5'     0\n",
       "vehbrand_'B6'     0\n",
       "vehgas_Diesel     0\n",
       "vehgas_Regular    0\n",
       "region_'R11'      0\n",
       "region_'R21'      0\n",
       "region_'R22'      0\n",
       "region_'R23'      0\n",
       "region_'R24'      0\n",
       "region_'R25'      0\n",
       "region_'R26'      0\n",
       "region_'R31'      0\n",
       "region_'R41'      0\n",
       "region_'R42'      0\n",
       "region_'R43'      0\n",
       "region_'R52'      0\n",
       "region_'R53'      0\n",
       "region_'R54'      0\n",
       "region_'R72'      0\n",
       "region_'R73'      0\n",
       "region_'R74'      0\n",
       "region_'R82'      0\n",
       "region_'R83'      0\n",
       "region_'R91'      0\n",
       "region_'R93'      0\n",
       "region_'R94'      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocessing X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_data = one_hot.transform(X_test[categorical_columns]).toarray()\n",
    "encoded_test_df = pd.DataFrame(encoded_test_data, columns=one_hot.get_feature_names_out(categorical_columns))\n",
    "test_cat_df = X_test[categorical_columns]\n",
    "X_test = pd.concat([X_test, encoded_test_df], axis=1).drop(categorical_columns,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Model instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'n_estimators' : 1000,\n",
    "    \"learning_rate\": 0.00001,\n",
    "    \"max_depth\" : 5,\n",
    "    \"subsample\" : 0.8,\n",
    "    \"colsample_bytree\" : 0.8,\n",
    "    \"gamma\" : 0,\n",
    "    \"min_child_weight\" : 1,\n",
    "    \"objective\" : 'reg:tweedie',\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "}\n",
    "\n",
    "bst = XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Unsupported type for weight', \"<class 'str'>\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bjzim/repos/mtpl2/2-baseline.ipynb Cell 85\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/bjzim/repos/mtpl2/2-baseline.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bst\u001b[39m.\u001b[39;49mfit(X_train,y_train, sample_weight\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mexposure\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/sklearn.py:1051\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[1;32m   1050\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1051\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1052\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1053\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1054\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1055\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1056\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1057\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1058\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1059\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1060\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1061\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1062\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1063\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1064\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1065\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1066\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1067\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1068\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1071\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/sklearn.py:534\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    515\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    516\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    535\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    536\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    537\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    538\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    539\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    540\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    541\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    542\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    543\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    544\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    545\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    546\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    550\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/sklearn.py:959\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:868\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n\u001b[0;32m--> 868\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_info(\n\u001b[1;32m    869\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m    870\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    871\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    872\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    873\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    874\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m    875\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m    876\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m feature_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39m=\u001b[39m feature_names\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:933\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_label(label)\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_weight(weight)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m base_margin \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_base_margin(base_margin)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:1089\u001b[0m, in \u001b[0;36mDMatrix.set_weight\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set weight of each instance.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \n\u001b[1;32m   1074\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \n\u001b[1;32m   1086\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m-> 1089\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, weight, \u001b[39m\"\u001b[39;49m\u001b[39mweight\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/data.py:1257\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     _meta_from_numpy(array, name, dtype, handle)\n\u001b[1;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnsupported type for \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name, \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(data)))\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Unsupported type for weight', \"<class 'str'>\")"
     ]
    }
   ],
   "source": [
    "bst.fit(X_train,y_train, sample_weight=exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjzim/repos/mtpl2/.venv/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [12:13:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806.7980910594765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0013531069429639775"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
